#!/usr/bin/env python3
"""
Test script for the enhanced job parser
"""
import asyncio
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'app'))

from services.enhanced_job_parser import enhanced_job_parser

async def test_job_parser():
    """Test the enhanced job parser"""
    if not enhanced_job_parser:
        print("âŒ Job parser not initialized")
        return
    
    print("ğŸ”§ Testing Enhanced Job Parser...")
    
    # Test 1: Check if parser is working
    test_result = enhanced_job_parser.test_parser()
    print(f"âœ… Parser test: {'PASSED' if test_result else 'FAILED'}")
    
    # Test 2: Check system dependencies
    deps = enhanced_job_parser.check_system_dependencies()
    print(f"ğŸ” System dependencies: {deps}")
    
    # Test 3: Test URL validation
    test_url = "https://www.linkedin.com/jobs/collections/recommended/?currentJobId=4027743206"
    is_valid = enhanced_job_parser._is_valid_linkedin_job_url(test_url)
    print(f"ğŸ”— URL validation: {'PASSED' if is_valid else 'FAILED'}")
    
    # Test 4: Test job ID extraction
    job_id = enhanced_job_parser._extract_job_id_from_url(test_url)
    print(f"ğŸ†” Job ID extraction: {job_id}")
    
    # Test 5: Test direct URL construction
    if job_id:
        direct_url = enhanced_job_parser._construct_direct_job_url(job_id)
        print(f"ğŸ”— Direct URL: {direct_url}")
        
        # Test 6: Test actual scraping (this will take time)
        print("\nğŸŒ Testing actual LinkedIn scraping...")
        try:
            result = await enhanced_job_parser.scrape_linkedin_job(test_url)
            if result:
                print("âœ… Scraping successful!")
                print(f"ğŸ“ Title: {result.get('title', 'N/A')}")
                print(f"ğŸ¢ Company: {result.get('company', {}).get('name', 'N/A')}")
                print(f"ğŸ“ Location: {result.get('location', {}).get('full_location', 'N/A')}")
                print(f"ğŸ“„ Description length: {len(result.get('description', ''))}")
            else:
                print("âŒ Scraping failed")
        except Exception as e:
            print(f"âŒ Scraping error: {e}")
    else:
        print("âŒ Could not extract job ID")

if __name__ == "__main__":
    print("ğŸš€ Testing Enhanced Job Parser...")
    asyncio.run(test_job_parser())
